Research-engineering-intern-assignment
Social Media Analytics Dashboard
A comprehensive research engineering assignment designed to visualize and analyze social media data. This project features a modern React-based dashboard for interactive data exploration and a Python-based data processing pipeline for sentiment analysis, topic modeling, and network graph generation.

Dashboard Preview Deplyoed link :- https://research-media-project.netlify.app/

üöÄ Features
Overview Dashboard: High-level metrics on posts, authors, and sentiment trends.
Event Correlation: Correlate social media spikes with real-world events to understand external triggers.
Narrative Analysis: Topic modeling using Latent Dirichlet Allocation (LDA) to discover hidden themes.
Network Visualization: Interactive force-directed graph showing relationships between authors and domains.
Analyst Copilot: An AI-powered chat interface to query top sources, analyze specific domains, and search for trends.
Sentiment Analysis: VADER-based sentiment scoring for all posts.
üõ†Ô∏è Tech Stack
Frontend: React, TypeScript, Vite, Tailwind CSS
Visualization: Recharts, React Force Graph
Styling: Tailwind CSS, Lucide React (Icons)
Data Processing: Python 3.x
Analysis Libraries: pandas, scikit-learn (Topic Modeling), vaderSentiment (Sentiment), NetworkX (Graph Theory)
üìã Prerequisites
Before you begin, ensure you have the following installed:

Node.js (v18 or higher)
npm (usually comes with Node.js)
Python (v3.8 or higher)
‚öôÔ∏è Setup & Installation
1. Clone the Repository
git clone <repository-url>
cd research-engineering-intern-assignment
2. Frontend Setup
Navigate to the UI directory and install dependencies:

cd my-data-ui
npm install
3. Python Environment Setup
It is recommended to use a virtual environment for the data processing scripts.

Windows:

# Create virtual environment
python -m venv venv

# Activate it
.\venv\Scripts\Activate

# Install dependencies
pip install -r requirements.txt
macOS/Linux:

python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
üìä Data Pipeline
The dashboard relies on pre-computed JSON data generated by the Python script. This ensures the frontend remains fast and responsive.

Ensure your raw data is located at my-data-ui/public/data.json (or ensure the script points to the correct source).
Run the analysis script:
# From the my-data-ui directory
python scripts/precompute_analysis.py
This command will generate the following files in public/precomputed/:

overview.json
topics.json
network.json
sentiment.json
event_correlations.json
Note: If you deploy this application, ensure these generated files are committed to your repository, as the Python script does not run in the browser.

üñ•Ô∏è Running Locally
To start the development server:

# Inside my-data-ui directory
npm run dev
Open your browser and navigate to http://localhost:5173 (or the port shown in your terminal).

üì¶ Building for Production
To create a production-ready build:

npm run build
This will generate a dist folder containing the static assets. You can preview the production build locally using:

npm run preview
üöÄ Deployment
This project is optimized for deployment on platforms like Vercel or Netlify.

Push to GitHub: Ensure your code (including public/precomputed files) is pushed to a GitHub repository.
Connect to Vercel: Import the project.
Settings:
Framework Preset: Vite
Build Command: npm run build
Output Directory: dist

Deploy: https://research-media-project.netlify.app/
